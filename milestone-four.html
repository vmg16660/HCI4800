<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>milestone 4</title>
    <link rel="stylesheet" href="css/milestone4style.css">
</head>
<div class="navbar">
    <a class="navlink" href="index.html">Home</a>
    <h1>HCI 4800 Team: Black Mongoose</h1> 
    <a class="navlink" href="members.html">Members</a>
    <a class="navlink" href="milestonelinks.html">Milestone Links</a>
</div>

<div class="homebody">
<h1>Milestone 4</h1>
<h2>Part A: High Fidelity Prototype</h2>
<ul>
    <li><a href="./figma-files/CSCI 4800 Prototypes.fig" download>High Fidelity Prototypes .fig</a></li>
</ul>
<p>**Note: demos, user story descriptions, and additional sources are included within the .fig file**</p>

<h2>Part B: Testing Protocol</h2>
<h3>1. Our research question and methodology of testing</h3>
<p>To assess the comparative efficiency of a new prototype registration system in relation to Athena, the existing system, a controlled experiment involving two groups of participants is being conducted. The primary objective of this experiment is to address the research inquiry: Does our registration system enable students to register with greater efficiency compared to Athena's current system?</p>
<p>The first group, designated as the control group, will utilize the Athena registration system, while the second group, referred to as the experimental group, will utilize the new prototype system. To determine an appropriate sample size for this study, guidance from Krejcie and Morgan's sample size determination table (1970) is being followed [1]. This authoritative source provides a comprehensive framework for establishing the sample size required to achieve reliable results.</p>
<p>Considering the population size of students at our institution, a representative sample of UGA students will be selected to partake in the experiment. The study involves observing student participants as they engage in a scripted user experience, specifically the registration process for a predetermined list of courses, such as software engineering and physical education. To minimize bias and ensure consistency, all student participants will be assigned the same set of courses to register for. The duration taken by each student participant to complete the registration process, whether using the Athena system or the prototype, will be recorded.</p>
<p>By comparing the registration completion times between the control and experimental groups, an evaluation of the new prototype system's efficiency in contrast to the current Athena system will be conducted. Previous studies have emphasized the significance of efficient registration systems in enhancing student satisfaction and alleviating stress levels during the registration process. An improved system has the potential to streamline the registration experience, allowing students to dedicate their attention to academic pursuits rather than administrative tasks. This experiment aims to gather empirical evidence to support the implementation of the new prototype system, ultimately benefiting both the institution and its students.</p>
<p>At the end of our experiment, we will have a required survey that is to be taken by the participants of said experiment. We will have the survey ask these 4 main questions in order to determine if our experiment was a success. The first question will be: “did you run into any Challenges with the system in the experiment?” This is an important first question since it will help us better gauge if there were any unforeseen issues with our prototype and find out how the students handled the new system overall compared to the old system. The second question that will be asked in the experiment is: “did it feel easy registering?” This question is important in gauging the level of difficulty that the students had when registering with our prototype compared to Athena. The third question that will be asked is: “were you able to find everything easily?” This question lets us know the degree of difficulty encountered by the students and see if it compares to the level of difficulty of Athena.</p>
<p>When looking for what type of response options we would have for the survey, we decided to use the Likert Scale Examples for surveys [2]. We decided that the best option for the response options would be a slider that goes from disagree strongly to agree strongly. The exact order of the options would be disagree strongly, disagree, slightly disagree, slightly agree, agree, and agree strongly. This ensures that the sentiments about our system will be accurate and accounts for how the students truly feel. After the students are done taking the survey, we will average them out so that we can get a good picture about how our system holds up when compared to Athena’s registration system.</p>

<h3>2. Describing our testing procedure</h3>

<h4>What is your specific plan to deal with informed consent?</h4>
<p>Our plan is to inform volunteers that they will be given a list of courses to register for using either Athena or our registration system. We would inform them that they will be monitored by an observer, either in person, through Zoom, or through software, and they may have to share their screen depending on the type of observation we would use or whose equipment we use. If proctoring software is used for the observation of the study, we will explain that it will only monitor the time, button clicks, and completion of tasks. We would also let them know that the courses are not actually being registered for, and that this is just a test to see which system is more efficient. Lastly, we also make sure that the volunteers understand and comprehend what will happen and then ask for their consent for their participation and observation in the study. Thus, this meets the three elements of informed consent that the Belmont Report outlines [3].</p>

<h4>What specific data will you collect and how will it be organized?</h4>
<p>We plan on collecting data to answer these specific questions: were subjects able to complete the tasks assigned to them, how much time did it take to complete the tasks, and how many steps did it take to complete the tasks. The questions were provided from the University of Washington, “Conducting a Usability Test” web article [4]. These questions will help us provide answers to whether our design solves the problems stated in our problem statement. We will collect the data by conducting an observational experiment between the control group using the original Athena registration page and the experimental group using our redesign of the registration page. The two groups will be given a script of the tasks one must complete during the study. There will be an observer who will time the event and take note of the number of steps it takes to complete each task. The observer role may also be automated for more accurate results. But specific consent would also be needed for users to have their computers monitored with software.</p>

<h4>What type of analysis do you intend to perform with the study data, and how will that analysis help answer your research question from (B.1)?</h4>
<p>For question 1, we are collecting the amount of “yes” answers and comparing the amount to the amount of “no'' answers. For “no'' answers, we will inquire about what happened during the experiment to find if it was a technical issue or due to design. If it was a technical issue, we may reconduct the test or remove the volunteer’s data from the experiment. If it was caused by design, we will take note of the design issue.</p>
<p>For question 2, we are collecting the total time it takes for each participant to finish the assigned tasks. We would then compare the average time for the control group against the average time for the experimental group. For testing the significance of our data, our null hypothesis is that the experimental group’s average time is greater or equal to the control group’s time. Our alternate hypothesis is that the experimental group’s average time is less than the control group’s time. Our significance level will be 0.05 as the article by the American Statistical Association (ASA) argues that “0.05 is a reasonable default significance level” [5]. If our p-value is less than the significance level, we can reject our null hypothesis and argue that our design was successful in making the act of registering more efficient. Thus, being a solution to our problem statement.</p>
<p>For question 3, we will collect data through observation to see how many buttons were clicked for a user to complete the same task from the control group and experimental group. We will consider our design successful if for each task, the experimental group used less or equal amount of button clicks than the control group. Thus, also adding to the argument that our design is a solution to our problem statement.</p>

<h4>How might you conduct your testing procedure safely during a pandemic?</h4>
<p>Participants would partake in the experiment using their own equipment and at home. Depending on the observation method, we may use zoom and ask for participants to share their screen. In which consent will be asked beforehand. Or use proctoring software as mentioned before. We would also adhere to any governmental guidelines regarding the pandemic.</p>

<h2>Summary Video</h2>
<ul>
    <li><a href="https://youtu.be/th1757wt7a0">Summary Video</a></li>
</ul>

<h2>Sources</h2>
<ol>
    <li><a href="https://www.researchgate.net/publication/349118299_Sample_Size_Determination_Using_Krejcie_and_Morgan_Table">https://www.researchgate.net/publication/349118299_Sample_Size_Determination_Using_Krejcie_and_Morgan_Table</a></li>
    <li><a href="https://www.extension.iastate.edu/documents/anr/likertscaleexamplesforsurveys.pdf">https://www.extension.iastate.edu/documents/anr/likertscaleexamplesforsurveys.pdf</a></li>
    <li><a href="https://www.hhs.gov/ohrp/regulations-and-policy/belmont-report/read-the-belmont-report/index.html#xinform">https://www.hhs.gov/ohrp/regulations-and-policy/belmont-report/read-the-belmont-report/index.html#xinform</a></li>
    <li><a href="https://www.washington.edu/accesscomputing/webd2/student/unit6/module2/lesson1.html">https://www.washington.edu/accesscomputing/webd2/student/unit6/module2/lesson1.html</a></li>
    <li><a href="https://www.statisticsteacher.org/2017/01/05/why-0-05-two-examples-that-put-students-in-the-role-of-decision-maker/">https://www.statisticsteacher.org/2017/01/05/why-0-05-two-examples-that-put-students-in-the-role-of-decision-maker/</a></li>
</ol>


</div>
</html>